# Cerebras

[Cerebras](https://inference-docs.cerebras.ai/resources/openai) supports the OpenAI client, allowing you to use the
[`openai-generic`](/ref/llm-client-providers/openai-generic) provider with an
overridden `base_url`.

See [OpenAI Generic](/ref/llm-client-providers/openai-generic) for more details about parameters.

**Example:**

```baml BAML
client<llm> CerebrasLlama {
  provider "openai-generic"
  options {
    base_url "https://api.cerebras.ai/v1"
    api_key env.CEREBRAS_API_KEY
    model "llama-3.3-70b"
  }
}
```
